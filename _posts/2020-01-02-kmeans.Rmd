---
layout: post
title: Kmeans Clustering
use-site-title: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

Step 1. Choose the K number of clusters.

Step 2. Split the data randomly into K groups.  

Step 3. Iterate the following until the cluster assignments stop changing or until the predetermined number of iterations:

  a) For each of the K clusters, compute the cluster centroid. The kth cluster centroid is the vector of the p feature means for the observations in the kth cluster. 
  b) Assign each observation to the cluster whose centroid is the closest. 


Here we will work with the Iris data. 
```{r}
data(iris)

iris_data <- iris %>% 
  select(c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width))
```

```{r echo=FALSE}
pcs <- as.data.frame(prcomp(t(iris_data))$rotation)

(current_clust <- ggplot(pcs, aes(PC1, PC2, color = iris$Species)) + 
  geom_point() + 
    theme_bw()  +
    ggsci::scale_color_aaas(name = "Species"))
```


## Step 1. Choose K number of clusters: 
```{r}
K <- 2
```


## Step 2. Split the data randomly into K groups:
```{r}
set.seed(10)
# Randomly assign a number, from 1 to K, to each of the observations. 
rand_idx <- sample(c(TRUE, FALSE), nrow(iris_data), replace=TRUE, prob=c(0.5, 0.5))

iris_data$cluster_id <- rand_idx
```


```{r echo=FALSE}
pcs <- as.data.frame(prcomp(t(iris_data))$rotation)

(current_clust <- ggplot(pcs, aes(PC1, PC2, color = iris_data$cluster_id )) + 
  geom_point() + 
    theme_bw()  +
    ggsci::scale_color_aaas(name = "Species"))
```






